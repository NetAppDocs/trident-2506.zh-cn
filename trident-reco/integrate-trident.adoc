---
sidebar: sidebar 
permalink: trident-reco/integrate-trident.html 
keywords: kubernetes, clusters, nodes, components, master, compute, fsx, flexgroup, flexvolume, solidfire, hci, virtual pool, cvs, gcp, volumes 
summary: Kubernetes 集群通常由两种类型的节点组成，每种节点负责不同的功能方面。 
---
= 整合Trident
:hardbreaks:
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
要集成Trident，需要集成以下设计和架构元素：驱动程序选择和部署、存储类设计、虚拟池设计、持久卷声明 (PVC) 对存储配置的影响、卷操作以及使用Trident部署 OpenShift 服务。



== 驾驶员选择和部署

为您的存储系统选择并部署后端驱动程序。



=== ONTAP后端驱动程序

ONTAP后端驱动程序的区别在于所使用的协议以及在存储系统上配置卷的方式。因此，在决定部署哪位驾驶员时要仔细考虑。

从更高的层面来看，如果您的应用程序具有需要共享存储的组件（多个 pod 访问同一个 PVC），则基于 NAS 的驱动程序将是默认选择，而基于块的 iSCSI 驱动程序则满足非共享存储的需求。根据应用程序的要求以及存储和基础设施团队的接受程度来选择协议。一般来说，对于大多数应用来说，它们之间几乎没有区别，因此通常取决于是否需要共享存储（多个 pod 需要同时访问）。

可用的ONTAP后端驱动程序有：

* `ontap-nas`每个已配置的 PV 都是一个完整的ONTAP FlexVolume。
* `ontap-nas-economy`每个已配置的 PV 都是一个 qtree，每个 FlexVolume 的 qtree 数量可配置（默认值为 200）。
* `ontap-nas-flexgroup`每个 PV 都配置为一个完整的ONTAP FlexGroup，并且分配给 SVM 的所有聚合都将被使用。
* `ontap-san`每个已配置的 PV 都是其自身 FlexVolume 中的一个 LUN。
* `ontap-san-economy`每个已配置的 PV 都是一个 LUN，每个 FlexVolume 的 LUN 数量可配置（默认值为 100）。


在三个 NAS 驱动程序之间进行选择会对应用程序可用的功能产生一些影响。

请注意，在下表中，并非所有功能都通过Trident公开。如果需要某些功能，则必须由存储管理员在配置完成后应用这些功能。上标脚注区分了每个功能和驱动程序的具体功能。

[cols="20,10,10,10,10,10,10,10"]
|===
| ONTAP NAS 驱动程序 | Snapshot | 克隆 | 动态出口策略 | 多附件 | QoS | 调整大小 | 复制 


| `ontap-nas` | 是 | 是 | 是的脚注：5[] | 是 | 是的脚注：1[] | 是 | 是的脚注：1[] 


| `ontap-nas-economy` | 无脚注：3[] | 无脚注：3[] | 是的脚注：5[] | 是 | 无脚注：3[] | 是 | 无脚注：3[] 


| `ontap-nas-flexgroup` | 是的脚注：1[] | 否 | 是的脚注：5[] | 是 | 是的脚注：1[] | 是 | 是的脚注：1[] 
|===
Trident为ONTAP提供 2 款 SAN 驱动程序，其功能如下所示。

[cols="20,10,10,10,10,10,10,10"]
|===
| ONTAP SAN 驱动程序 | Snapshot | 克隆 | 多附件 | 双向 CHAP | QoS | 调整大小 | 复制 


| `ontap-san` | 是 | 是 | 是的脚注：4[] | 是 | 是的脚注：1[] | 是 | 是的脚注：1[] 


| `ontap-san-economy` | 是 | 是 | 是的脚注：4[] | 是 | 无脚注：3[] | 是 | 无脚注：3[] 
|===
[verse]
以上表格的脚注：是脚注1[]：非Trident管理；是脚注2[]：由Trident管理，但不支持PV粒度；否脚注3[]：非Trident管理且不支持PV粒度；是脚注4[]：支持原始块卷；是脚注5[]： Trident支持。

非 PV 粒度的功能将应用于整个 FlexVolume，所有 PV（即共享 FlexVol 中的 qtree 或 LUN）将共享一个共同的计划。

如上表所示，大部分功能都体现在以下方面： `ontap-nas`和 `ontap-nas-economy`是一样的。然而，因为 `ontap-nas-economy`驱动程序限制了以 PV 粒度控制计划的能力，这可能会特别影响您的灾难恢复和备份计划。对于希望在ONTAP存储上利用 PVC 克隆功能的开发团队而言，只有在使用以下配置时才有可能： `ontap-nas` ， `ontap-san`或者 `ontap-san-economy`司机。


NOTE: 这 `solidfire-san`驱动程序还能够克隆PVC。



=== Cloud Volumes ONTAP后端驱动程序

Cloud Volumes ONTAP提供数据控制以及企业级存储功能，适用于各种用例，包括文件共享和块级存储，支持 NAS 和 SAN 协议（NFS、SMB / CIFS 和 iSCSI）。 Cloud Volume ONTAP的兼容驱动程序有： `ontap-nas` ， `ontap-nas-economy` ， `ontap-san`和 `ontap-san-economy`。这些适用于 Azure 版 Cloud Volume ONTAP和 GCP 版 Cloud Volume ONTAP 。



=== Amazon FSx for ONTAP后端驱动程序

Amazon FSx for NetApp ONTAP让您能够利用您熟悉的NetApp功能、性能和管理能力，同时享受在 AWS 上存储数据的简单性、敏捷性、安全性和可扩展性。  FSx for ONTAP支持许多ONTAP文件系统功能和管理 API。  Cloud Volume ONTAP的兼容驱动程序有： `ontap-nas` ， `ontap-nas-economy` ， `ontap-nas-flexgroup` ， `ontap-san`和 `ontap-san-economy`。



=== NetApp HCI/ SolidFire后端驱动程序

这 `solidfire-san`该驱动程序与NetApp HCI/ SolidFire平台配合使用，可帮助管理员根据 QoS 限制为Trident配置 Element 后端。如果您希望设计后端以设置Trident所配置卷的特定 QoS 限制，请使用以下方法： `type`后端文件中的参数。管理员还可以使用以下方法限制可在存储上创建的卷大小： `limitVolumeSize`范围。目前，Element 存储功能（例如卷调整大小和卷复制）尚不支持通过以下方式进行存储： `solidfire-san`司机。这些操作应该通过 Element Software 的 Web 用户界面手动完成。

[cols="20,10,10,10,10,10,10,10"]
|===
| SolidFire驱动程序 | Snapshot | 克隆 | 多附件 | CHAP | QoS | 调整大小 | 复制 


| `solidfire-san` | 是 | 是 | 是的脚注：2[] | 是 | 是 | 是 | 是的脚注：1[] 
|===
[verse]
脚注：是脚注1： Trident不管理 是脚注2：支持原始块卷



=== Azure NetApp Files后端驱动程序

Trident使用 `azure-netapp-files`司机管理link:https://azure.microsoft.com/en-us/services/netapp/["Azure NetApp Files"^]服务。

有关此驱动程序及其配置方法的更多信息，请参见此处。link:https://docs.netapp.com/us-en/trident/trident-use/anf.html["用于Azure NetApp Files的Trident后端配置"^] 。

[cols="20,10,10,10,10,10,10"]
|===
| Azure NetApp Files驱动程序 | Snapshot | 克隆 | 多附件 | QoS | 展开 | 复制 


| `azure-netapp-files` | 是 | 是 | 是 | 是 | 是 | 是的脚注：1[] 
|===
[verse]
脚注：是脚注：1[]：并非由Trident管理



=== Google Cloud 后端驱动程序上的Cloud Volumes Service

Trident使用 `gcp-cvs`用于连接 Google Cloud 上的Cloud Volumes Service的驱动程序。

这 `gcp-cvs`驱动程序使用虚拟池来抽象后端，并允许Trident确定卷放置位置。管理员在以下位置定义虚拟池： `backend.json`文件。存储类使用选择器按标签识别虚拟池。

* 如果后端定义了虚拟池， Trident将尝试在 Google Cloud 存储池中创建卷，而这些虚拟池仅限于这些存储池。
* 如果后端未定义虚拟池， Trident将从该区域的可用存储池中选择一个 Google Cloud 存储池。


要在Trident上配置 Google Cloud 后端，您必须指定 `projectNumber`， `apiRegion` ， 和 `apiKey`在后端文件中。您可以在 Google Cloud 控制台中找到项目编号。  API 密钥取自您在 Google Cloud 上为Cloud Volumes Service设置 API 访问权限时创建的服务帐户私钥文件。

有关 Google Cloud 上的Cloud Volumes Service服务类型和服务级别的详细信息，请参阅：link:../trident-use/gcp.html["了解Trident对 GCP 版 CVS 的支持"] 。

[cols="20,10,10,10,10,10,10"]
|===
| 适用于 Google Cloud Drive 的Cloud Volumes Service | Snapshot | 克隆 | 多附件 | QoS | 展开 | 复制 


| `gcp-cvs` | 是 | 是 | 是 | 是 | 是 | 仅适用于 CVS-Performance 服务类型。 
|===
[NOTE]
====
.复制说明
* 复制功能并非由Trident管理。
* 克隆卷将创建在与源卷相同的存储池中。


====


== 存储类设计

要创建 Kubernetes 存储类对象，需要对各个存储类进行配置和应用。本节讨论如何为您的应用程序设计存储类。



=== 具体后端利用

在特定的存储类对象中可以使用过滤来确定要与该特定存储类一起使用的存储池或存储池集。存储类中可以设置三组过滤器： `storagePools` ， `additionalStoragePools`和/或 `excludeStoragePools`。

这 `storagePools`该参数有助于将存储限制在与任何指定属性匹配的存储池集合中。这 `additionalStoragePools`该参数用于扩展Trident用于配置的池集，以及由属性选择的池集。 `storagePools`参数。您可以单独使用其中一个参数，也可以同时使用这两个参数，以确保选择合适的存储池集。

这 `excludeStoragePools`该参数用于专门排除符合属性要求的已列出泳池集合。



=== 模拟 QoS 策略

如果您希望设计存储类来模拟服务质量策略，请创建一个具有以下功能的存储类： `media`属性为 `hdd`或者 `ssd`。基于 `media`根据存储类中提到的属性， Trident将选择合适的后端来提供服务。 `hdd`或者 `ssd`将聚合与媒体属性匹配，然后将卷的配置定向到特定的聚合上。因此，我们可以创建一个 PREMIUM 存储类，它将具有 `media`属性集为 `ssd`这可以归类为高级 QoS 策略。我们可以创建另一个存储类 STANDARD，其媒体属性设置为“hdd”，这可以归类为 STANDARD QoS 策略。我们还可以使用存储类中的“IOPS”属性将配置重定向到 Element 设备，该设备可以定义为 QoS 策略。



=== 根据特定功能使用后端

存储类可以设计为在特定的后端上指导卷配置，其中启用了精简配置和厚配置、快照、克隆和加密等功能。要指定要使用的存储，请创建存储类，指定启用所需功能的相应后端。



=== 虚拟池

所有Trident后端均可使用虚拟池。你可以使用Trident提供的任何驱动程序，为任何后端定义虚拟池。

虚拟池允许管理员在后端之上创建一个抽象层，可以通过存储类引用该抽象层，从而在后端上更灵活、更高效地放置卷。同一服务类别可以定义不同的后端。此外，可以在同一个后端创建多个具有不同特性的存储池。当使用具有特定标签的选择器配置存储类时， Trident会选择与所有选择器标签匹配的后端来放置卷。如果存储类别选择器标签与多个存储池匹配， Trident将从中选择其中一个来配置卷。



== 虚拟泳池设计

创建后端时，通常可以指定一组参数。管理员无法创建具有相同存储凭据和不同参数集的另一个后端。随着虚拟池的引入，这个问题得到了缓解。虚拟池是在后端和 Kubernetes 存储类之间引入的级别抽象，以便管理员可以定义参数以及可以通过 Kubernetes 存储类作为选择器引用的标签，以与后端无关的方式。可以使用Trident为所有受支持的NetApp后端定义虚拟池。该列表包括SolidFire/ NetApp HCI、 ONTAP、GCP 上的Cloud Volumes Service以及Azure NetApp Files。


NOTE: 定义虚拟池时，建议不要尝试在后端定义中重新排列现有虚拟池的顺序。此外，建议不要编辑/修改现有虚拟池的属性，而是定义一个新的虚拟池。



=== 模拟不同的服务级别/QoS

可以设计虚拟池来模拟服务类。使用Azure NetApp Files云卷服务的虚拟池实现，让我们来研究如何设置不同的服务类。配置Azure NetApp Files后端，使用多个标签来表示不同的性能级别。放 `servicelevel`将各个方面调整到相应的性能水平，并在每个标签下添加其他所需的方面。现在创建不同的 Kubernetes 存储类，将它们映射到不同的虚拟池。使用 `parameters.selector`字段中，每个 StorageClass 都会指定哪些虚拟池可用于托管卷。



=== 指定一组特定的方面

可以从单个存储后端设计多个具有特定功能的虚拟池。为此，请在后端配置多个标签，并在每个标签下设置所需的方面。现在使用以下方式创建不同的 Kubernetes 存储类： `parameters.selector`该字段将映射到不同的虚拟池。后端配置的卷将具有所选虚拟池中定义的方面。



=== 影响存储供应的PVC特性

在创建 PVC 时，除请求的存储类别之外的某些参数可能会影响Trident 的配置决策过程。



=== 访问模式

通过 PVC 请求存储时，必填字段之一是访问模式。所需的模式可能会影响用于托管存储请求的后端选择。

Trident将尝试根据以下矩阵将所使用的存储协议与指定的访问方法进行匹配。这与底层存储平台无关。

[cols="20,30,30,30"]
|===
|  | 读写一次 | 只读多 | 读写多 


| iSCSI | 是 | 是 | 是的（原始块） 


| NFS | 是 | 是 | 是 
|===
如果向未配置 NFS 后端的Trident部署提交 ReadWriteMany PVC 请求，则不会配置任何卷。因此，请求者应该使用适合其应用的访问模式。



== 卷操作



=== 修改持久卷

除两种例外情况外，持久卷是 Kubernetes 中的不可变对象。创建完成后，可以修改回收策略和大小。然而，这并不能阻止在 Kubernetes 之外修改卷的某些方面。为了针对特定应用定制卷，确保容量不会意外耗尽，或者出于任何原因将卷移动到不同的存储控制器，这样做可能是可取的。


NOTE: 目前 Kubernetes 树内配置器不支持对 NFS、iSCSI 或 FC PV 进行卷大小调整操作。  Trident支持扩展 NFS、iSCSI 和 FC 卷。

PV的连接详情创建后无法修改。



=== 创建按需卷快照

Trident支持按需创建卷快照，并支持使用 CSI 框架从快照创建 PVC。快照提供了一种便捷的方法来维护数据在特定时间点的副本，并且在 Kubernetes 中具有独立于源 PV 的生命周期。这些快照可用于克隆PVC。



=== 从快照创建卷

Trident还支持从卷快照创建持久卷。要实现这一点，只需创建一个 PersistentVolumeClaim 并指定 `datasource`作为创建卷所需的快照。 Trident将通过创建一个包含快照中数据的卷来处理此 PVC。借助此功能，可以跨区域复制数据、创建测试环境、完全替换损坏或已损坏的生产卷，或者检索特定文件和目录并将其传输到另一个附加卷。



=== 在集群中移动卷

存储管理员能够在ONTAP集群中，在聚合和控制器之间移动卷，而不会对存储用户造成任何干扰。只要目标聚合是Trident使用的 SVM 可以访问的目标聚合，此操作就不会影响Trident或 Kubernetes 集群。重要的是，如果聚合体是新添加到 SVM 中的，则需要通过将其重新添加到Trident来刷新后端。这将触发Trident重新清点 SVM，以便识别新的聚合体。

但是， Trident并不自动支持跨后端移动卷。这包括在同一集群中的 SVM 之间、集群之间，或者到不同的存储平台（即使该存储系统是连接到Trident 的存储系统）。

如果将卷复制到另一个位置，则可以使用卷导入功能将当前卷导入到Trident中。



=== 扩大规模

Trident支持调整 NFS、iSCSI 和 FC PV 的大小。这样用户就可以直接通过 Kubernetes 层调整卷的大小。所有主流NetApp存储平台，包括ONTAP、 SolidFire/ NetApp HCI和Cloud Volumes Service后端，均可进行卷扩展。为了便于日后扩展，请设置 `allowVolumeExpansion`到 `true`在与该卷关联的 StorageClass 中。每当需要调整持久卷的大小时，请编辑以下内容： `spec.resources.requests.storage`在持久卷声明中添加对所需卷大小的注释。  Trident会自动处理存储集群上卷的大小调整。



=== 将现有卷导入 Kubernetes

卷导入功能允许将现有存储卷导入 Kubernetes 环境。目前这得到了以下方面的支持： `ontap-nas` ， `ontap-nas-flexgroup` ， `solidfire-san` ， `azure-netapp-files` ， 和 `gcp-cvs`司机。将现有应用程序移植到 Kubernetes 或灾难恢复场景中，此功能非常有用。

使用ONTAP时 `solidfire-san`司机们，请使用该命令 `tridentctl import volume <backend-name> <volume-name> -f /path/pvc.yaml`将现有卷导入 Kubernetes 以便由Trident管理。导入卷命令中使用的 PVC YAML 或 JSON 文件指向一个存储类，该存储类将Trident标识为配置程序。使用NetApp HCI/ SolidFire后端时，请确保卷名称是唯一的。如果卷名称重复，请将卷克隆为唯一名称，以便卷导入功能可以区分它们。

如果 `azure-netapp-files`或者 `gcp-cvs`使用了驱动程序，请使用命令 `tridentctl import volume <backend-name> <volume path> -f /path/pvc.yaml`将卷导入 Kubernetes 以便由Trident管理。这样就确保了卷号的唯一性。

执行上述命令后， Trident将在后端找到该卷并读取其大小。它会自动添加（必要时会覆盖）已配置的PVC的容积大小。然后Trident创建新的 PV，Kubernetes 将 PVC 绑定到 PV。

如果部署的集装箱需要特定的进口 PVC，则该集装箱将保持待定状态，直到通过批量进口流程绑定 PVC/PV 对为止。  PVC/PV管对连接好后，如果没有其他问题，容器应该就能升起来。



=== 注册服务

注册表存储的部署和管理已在文档中记录。link:https://netapp.io/["netapp.io"^]在link:https://netapp.io/2017/08/24/deploying-the-openshift-registry-using-netapp-storage/["博客"^]。



=== 日志服务

与其他 OpenShift 服务一样，日志服务使用 Ansible 进行部署，配置参数由提供给 playbook 的清单文件（又名 hosts）提供。本文将介绍两种安装方法：在 OpenShift 初始安装期间部署日志记录和在 OpenShift 安装完成后部署日志记录。


CAUTION: 从 Red Hat OpenShift 版本 3.9 开始，官方文档建议不要使用 NFS 作为日志服务，因为存在数据损坏方面的担忧。这是基于红帽公司对其产品的测试结果。 ONTAP NFS 服务器不存在这些问题，并且可以轻松地支持日志部署。最终，日志服务的协议选择取决于您，但要知道，在使用NetApp平台时，这两种协议都能很好地工作，如果您更喜欢 NFS，也没有理由避免使用 NFS。

如果选择将 NFS 与日志服务一起使用，则需要设置 Ansible 变量。 `openshift_enable_unsupported_configurations`到 `true`防止安装程序运行失败。



==== 开始使用

日志服务可以选择性地部署到应用程序以及 OpenShift 集群本身的核心操作中。如果您选择部署操作日志记录，请指定以下变量 `openshift_logging_use_ops`作为 `true`将创建该服务的两个实例。控制操作日志实例的变量中包含“ops”，而控制应用程序日志实例的变量则不包含。

根据部署方法配置 Ansible 变量非常重要，以确保底层服务使用正确的存储。让我们来看看每种部署方法的选项。


NOTE: 下表仅包含与日志服务相关的存储配置变量。您还可以找到其他选择link:https://docs.openshift.com/container-platform/3.11/install_config/aggregate_logging.html["Red Hat OpenShift 日志记录文档"^]应根据您的部署情况进行审查、配置和使用。

下表中的变量将使 Ansible playbook 使用提供的详细信息为日志服务创建 PV 和 PVC。虽然这种方法不如在 OpenShift 安装后使用组件安装 playbook 灵活，但如果您有现有的卷可用，这也不失为一个选择。

[cols="40,40"]
|===
| 变量 | 详细信息 


| `openshift_logging_storage_kind` | 设置为 `nfs`让安装程序为日志服务创建 NFS PV。 


| `openshift_logging_storage_host` | NFS主机的主机名或IP地址。这应该设置为虚拟机的 dataLIF。 


| `openshift_logging_storage_nfs_directory` | NFS导出挂载路径。例如，如果体积连接为 `/openshift_logging`你会将该路径用于此变量。 


| `openshift_logging_storage_volume_name` | 名称，例如 `pv_ose_logs`，创建 PV。 


| `openshift_logging_storage_volume_size` | 例如，NFS 导出的大小。 `100Gi` 。 
|===
如果您的 OpenShift 集群已经运行，因此Trident已经部署和配置，安装程序可以使用动态配置来创建卷。需要配置以下变量。

[cols="40,40"]
|===
| 变量 | 详细信息 


| `openshift_logging_es_pvc_dynamic` | 设置为 true 以使用动态配置卷。 


| `openshift_logging_es_pvc_storage_class_name` | PVC 中将使用的存储类别的名称。 


| `openshift_logging_es_pvc_size` | PVC中要求的体积大小。 


| `openshift_logging_es_pvc_prefix` | 日志记录服务使用的 PVC 前缀。 


| `openshift_logging_es_ops_pvc_dynamic` | 设置为 `true`为运维日志实例使用动态配置的卷。 


| `openshift_logging_es_ops_pvc_storage_class_name` | 运维日志实例的存储类名称。 


| `openshift_logging_es_ops_pvc_size` | 操作实例的卷请求大小。 


| `openshift_logging_es_ops_pvc_prefix` | 操作实例 PVC 的前缀。 
|===


==== 部署日志堆栈

如果您将日志记录部署作为 OpenShift 初始安装过程的一部分，那么您只需要遵循标准部署过程即可。  Ansible 将配置和部署所需的服务和 OpenShift 对象，以便在 Ansible 完成后立即提供该服务。

但是，如果在初始安装之后进行部署，则需要使用 Ansible 的组件 playbook。此过程可能因 OpenShift 版本不同而略有差异，因此请务必阅读并遵循相关说明。link:https://docs.openshift.com/container-platform/3.11/welcome/index.html["Red Hat OpenShift 容器平台 3.11 文档"^]适用于您的版本。



== 指标服务

指标服务为管理员提供有关 OpenShift 集群的状态、资源利用率和可用性的宝贵信息。此外，它对于 pod 自动扩展功能也是必要的，许多组织使用指标服务中的数据进行费用分摊和/或收益展示应用程序。

与日志服务以及整个 OpenShift 一样，Ansible 也用于部署指标服务。此外，与日志服务一样，指标服务可以在集群的初始设置期间或集群运行后使用组件安装方法进行部署。以下表格包含了为指标服务配置持久存储时重要的变量。


NOTE: 下表仅包含与指标服务相关的存储配置变量。文档中还有许多其他选项，应根据您的部署情况进行查看、配置和使用。

[cols="40,40"]
|===
| 变量 | 详细信息 


| `openshift_metrics_storage_kind` | 设置为 `nfs`让安装程序为日志服务创建 NFS PV。 


| `openshift_metrics_storage_host` | NFS主机的主机名或IP地址。这应该设置为你的 SVM 的 dataLIF。 


| `openshift_metrics_storage_nfs_directory` | NFS导出挂载路径。例如，如果体积连接为 `/openshift_metrics`你会将该路径用于此变量。 


| `openshift_metrics_storage_volume_name` | 名称，例如 `pv_ose_metrics`，用于创建 PV。 


| `openshift_metrics_storage_volume_size` | 例如，NFS 导出的大小。 `100Gi` 。 
|===
如果您的 OpenShift 集群已经运行，因此Trident已经部署和配置，安装程序可以使用动态配置来创建卷。需要配置以下变量。

[cols="40,40"]
|===
| 变量 | 详细信息 


| `openshift_metrics_cassandra_pvc_prefix` | 用于指标 PVC 的前缀。 


| `openshift_metrics_cassandra_pvc_size` | 请求的卷册数量。 


| `openshift_metrics_cassandra_storage_type` | 用于指标的存储类型，必须将其设置为动态，以便 Ansible 创建具有适当存储类的 PVC。 


| `openshift_metrics_cassanda_pvc_storage_class_name` | 要使用的存储类的名称。 
|===


=== 部署指标服务

在 hosts/inventory 文件中定义了相应的 Ansible 变量后，使用 Ansible 部署服务。如果您在安装 OpenShift 时进行部署，则 PV 将自动创建和使用。如果您使用组件 playbook 进行部署，则在 OpenShift 安装之后，Ansible 会创建所需的任何 PVC，并在Trident为其配置存储之后部署服务。

上述变量以及部署过程可能会随着 OpenShift 的每个版本而改变。请务必查看并遵循link:https://docs.openshift.com/container-platform/3.11/install_config/cluster_metrics.html["红帽 OpenShift 部署指南"^]请根据您的环境配置您的版本。
